"""
AI ìƒë‹´ ì„œë¹„ìŠ¤ - ì†Œìƒê³µì¸ íŠ¹í™” ìƒë‹´ ì‹œìŠ¤í…œ
"""
from typing import Dict, Any, Optional
from src.infrastructure.ai.gemini_service import GeminiService


class AIConsultantService(GeminiService):
    """ì†Œìƒê³µì¸ íŠ¹í™” AI ìƒë‹´ ì„œë¹„ìŠ¤"""
    
    def __init__(self, api_key: str):
        super().__init__(api_key)
        self.consultation_prompt = self._get_consultation_system_prompt()
    
    def _get_consultation_system_prompt(self) -> str:
        """ì†Œìƒê³µì¸ ìƒë‹´ ì „ìš© ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸"""
        return """
ë‹¹ì‹ ì€ í•œêµ­ì˜ ì†Œìƒê³µì¸ ì „ë¬¸ ê²½ì˜ ì»¨ì„¤í„´íŠ¸ì…ë‹ˆë‹¤.

**ì „ë¬¸ ë¶„ì•¼:**
- ìƒê¶Œ ë¶„ì„ ë° ì…ì§€ ì„ ì •
- ì—…ì¢…ë³„ ì°½ì—… ì „ëµ ìˆ˜ë¦½
- ë§ˆì¼€íŒ… ë° í™ë³´ ë°©ì•ˆ
- ì •ë¶€ ì§€ì›ì‚¬ì—… ë° ì œë„ ì•ˆë‚´
- ê²½ì˜ ê°œì„  ë° ìˆ˜ìµì„± í–¥ìƒ

**ë‹µë³€ ì›ì¹™:**
1. ì‹¤ìš©ì ì´ê³  êµ¬ì²´ì ì¸ ì¡°ì–¸ ì œê³µ
2. í•œêµ­ ì‹œì¥ ìƒí™©ì— ë§ëŠ” í˜„ì‹¤ì  ì†”ë£¨ì…˜
3. ë‹¨ê³„ë³„ ì‹¤í–‰ ê°€ëŠ¥í•œ ì•¡ì…˜ í”Œëœ ì œì‹œ
4. ê´€ë ¨ ì •ë¶€ ì§€ì›ì‚¬ì—…ì´ë‚˜ ì œë„ ì •ë³´ í¬í•¨
5. ë¹„ìš© íš¨ìœ¨ì ì¸ ë°©ì•ˆ ìš°ì„  ì œì•ˆ

**ë‹µë³€ í˜•ì‹:**
- ì¹œê·¼í•˜ê³  ì „ë¬¸ì ì¸ í†¤
- êµ¬ì²´ì ì¸ ìˆ«ìë‚˜ ì˜ˆì‹œ í¬í•¨
- ì‹¤í–‰ ë‹¨ê³„ë¥¼ ëª…í™•íˆ êµ¬ë¶„
- ì¶”ê°€ ì§ˆë¬¸ì´ë‚˜ ìƒë‹´ì´ í•„ìš”í•œ ë¶€ë¶„ ì•ˆë‚´

í•­ìƒ ì†Œìƒê³µì¸ì˜ ì…ì¥ì—ì„œ ìƒê°í•˜ê³ , ì‹¤ì œë¡œ ë„ì›€ì´ ë˜ëŠ” ì¡°ì–¸ì„ í•´ì£¼ì„¸ìš”.
"""

    async def get_consultation(self, 
                             question: str, 
                             business_type: Optional[str] = None,
                             region: Optional[str] = None,
                             budget: Optional[str] = None,
                             context: Optional[Dict[str, Any]] = None) -> Dict[str, Any]:
        """AI ìƒë‹´ ì‘ë‹µ ìƒì„±"""
        try:
            # ìƒë‹´ ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±
            context_info = self._build_consultation_context(
                business_type, region, budget, context
            )
            
            # ìƒë‹´ í”„ë¡¬í”„íŠ¸ ìƒì„±
            full_prompt = f"{self.consultation_prompt}\n\n{context_info}\n\nì‚¬ìš©ì ì§ˆë¬¸: {question}"
            
            # Gemini API í˜¸ì¶œ
            response = self.client.models.generate_content(
                model="gemma-3-27b-it",
                contents=full_prompt
            )
            
            # ì‘ë‹µ íŒŒì‹±
            answer = ""
            for part in response.candidates[0].content.parts:
                if part.text:
                    answer += part.text
            
            return {
                "answer": answer.strip(),
                "context": context_info,
                "question": question,
                "timestamp": self._get_current_timestamp()
            }
            
        except Exception as e:
            print(f"AI ìƒë‹´ ì˜¤ë¥˜: {e}")
            return self._get_fallback_consultation_response(question)
    
    def _build_consultation_context(self, 
                                  business_type: Optional[str] = None,
                                  region: Optional[str] = None,
                                  budget: Optional[str] = None,
                                  additional_context: Optional[Dict[str, Any]] = None) -> str:
        """ìƒë‹´ ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±"""
        context_parts = []
        
        if business_type:
            context_parts.append(f"ì—…ì¢…: {business_type}")
        
        if region:
            context_parts.append(f"ì§€ì—­: {region}")
            
        if budget:
            context_parts.append(f"ì˜ˆì‚°: {budget}")
            
        if additional_context:
            for key, value in additional_context.items():
                if value:
                    context_parts.append(f"{key}: {value}")
        
        if context_parts:
            return f"**ìƒë‹´ ì •ë³´:**\n" + "\n".join(f"- {part}" for part in context_parts) + "\n"
        
        return ""
    
    def _get_fallback_consultation_response(self, question: str) -> Dict[str, Any]:
        """ì„œë¹„ìŠ¤ ì˜¤ë¥˜ ì‹œ ëŒ€ì²´ ì‘ë‹µ"""
        fallback_responses = {
            "ìƒê¶Œ": "ìƒê¶Œ ë¶„ì„ì„ ìœ„í•´ì„œëŠ” ë‹¤ìŒì„ ê³ ë ¤í•´ë³´ì„¸ìš”:\n\n1. **ìœ ë™ì¸êµ¬ ì¡°ì‚¬**: ì‹œê°„ëŒ€ë³„, ìš”ì¼ë³„ ìœ ë™ì¸êµ¬ íŒ¨í„´ ë¶„ì„\n2. **ê²½ìŸì—…ì²´ í˜„í™©**: ë°˜ê²½ 500m ë‚´ ë™ì¢…ì—…ì²´ ìˆ˜ì™€ ìš´ì˜í˜„í™©\n3. **ì ‘ê·¼ì„±**: ëŒ€ì¤‘êµí†µ, ì£¼ì°¨ì‹œì„¤, ë„ë³´ ì ‘ê·¼ì„±\n4. **ì„ëŒ€ë£Œ ìˆ˜ì¤€**: ë§¤ì¶œ ëŒ€ë¹„ ì„ëŒ€ë£Œ ë¹„ìœ¨ 10-15% ê¶Œì¥\n\nì†Œìƒê³µì¸ì‹œì¥ì§„í¥ê³µë‹¨ì˜ ìƒê¶Œì •ë³´ì‹œìŠ¤í…œ(ìƒê¶Œë„·)ì„ í™œìš©í•´ë³´ì„¸ìš”.",
            
            "ì°½ì—…": "ì°½ì—… ì¤€ë¹„ ë‹¨ê³„ë³„ ì²´í¬ë¦¬ìŠ¤íŠ¸:\n\n1. **ì‹œì¥ì¡°ì‚¬**: ëª©í‘œ ê³ ê°ì¸µ, ì‹œì¥ ê·œëª¨, ê²½ìŸ í˜„í™©\n2. **ì‚¬ì—…ê³„íšì„œ**: ìˆ˜ìµëª¨ë¸, ë§ˆì¼€íŒ… ì „ëµ, ì¬ë¬´ê³„íš\n3. **ìê¸ˆì¡°ë‹¬**: ì°½ì—…ì§€ì›ê¸ˆ, ì •ì±…ìê¸ˆ, íˆ¬ì ìœ ì¹˜\n4. **ë²•ì  ì¤€ë¹„**: ì‚¬ì—…ìë“±ë¡, ê°ì¢… ì¸í—ˆê°€, ë³´í—˜ ê°€ì…\n\nì¤‘ì†Œë²¤ì²˜ê¸°ì—…ë¶€ì˜ ì°½ì—…ì§€ì›ì‚¬ì—…ì„ í™•ì¸í•´ë³´ì‹œê¸° ë°”ëë‹ˆë‹¤.",
            
            "ë§ˆì¼€íŒ…": "íš¨ê³¼ì ì¸ ì†Œìƒê³µì¸ ë§ˆì¼€íŒ… ë°©ë²•:\n\n1. **ì˜¨ë¼ì¸ ë§ˆì¼€íŒ…**: ë„¤ì´ë²„ í”Œë ˆì´ìŠ¤, ì¸ìŠ¤íƒ€ê·¸ë¨, ë¸”ë¡œê·¸\n2. **ì§€ì—­ë°€ì°©**: ë™ë„¤ ì»¤ë®¤ë‹ˆí‹°, ì „ë‹¨ì§€, í˜„ìˆ˜ë§‰\n3. **ê³ ê°ê´€ë¦¬**: ë‹¨ê³¨ ê³ ê° ìš°ëŒ€, ë¦¬ë·° ê´€ë¦¬, ì¶”ì²œ ì´ë²¤íŠ¸\n4. **í˜‘ë ¥ë§ˆì¼€íŒ…**: ì£¼ë³€ ìƒê¶Œê³¼ì˜ ê³µë™ í”„ë¡œëª¨ì…˜\n\nì†Œìƒê³µì¸ì‹œì¥ì§„í¥ê³µë‹¨ì˜ ë§ˆì¼€íŒ… ì§€ì›ì‚¬ì—…ë„ í™œìš©í•´ë³´ì„¸ìš”.",
            
            "ì§€ì›ì‚¬ì—…": "ì£¼ìš” ì†Œìƒê³µì¸ ì§€ì›ì‚¬ì—…:\n\n1. **ì†Œìƒê³µì¸ì‹œì¥ì§„í¥ê³µë‹¨**: ê²½ì˜ê°œì„ , ë§ˆì¼€íŒ…, êµìœ¡ì§€ì›\n2. **ì¤‘ì†Œë²¤ì²˜ê¸°ì—…ë¶€**: ì°½ì—…ì§€ì›ê¸ˆ, ê¸°ìˆ ê°œë°œì§€ì›\n3. **ì§€ìì²´ ì§€ì›**: ì§€ì—­ë³„ íŠ¹í™” ì§€ì›ì‚¬ì—…\n4. **ì˜¨ë¼ì¸ íŒë¡œ**: ì˜¨ë¼ì¸ì‡¼í•‘ëª° ì…ì  ì§€ì›\n\nì •ë¶€24ë‚˜ ì†Œìƒê³µì¸ì§€ì›ì„¼í„°ì—ì„œ ë” ìì„¸í•œ ì •ë³´ë¥¼ í™•ì¸í•˜ì„¸ìš”."
        }
        
        # í‚¤ì›Œë“œ ë§¤ì¹­ìœ¼ë¡œ ì ì ˆí•œ ì‘ë‹µ ì„ íƒ
        for keyword, response in fallback_responses.items():
            if keyword in question:
                return {
                    "answer": response,
                    "context": "",
                    "question": question,
                    "timestamp": self._get_current_timestamp(),
                    "fallback": True
                }
        
        # ê¸°ë³¸ ì‘ë‹µ
        return {
            "answer": """ì•ˆë…•í•˜ì„¸ìš”! ì†Œìƒê³µì¸ AI ìƒë‹´ì‚¬ì…ë‹ˆë‹¤. ğŸª

ê¶ê¸ˆí•œ ë‚´ìš©ì„ ì¢€ ë” êµ¬ì²´ì ìœ¼ë¡œ ë§ì”€í•´ ì£¼ì‹œë©´ ë” ì •í™•í•œ ë„ì›€ì„ ë“œë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

**ìƒë‹´ ê°€ëŠ¥ ë¶„ì•¼:**
â€¢ ğŸ“ ìƒê¶Œ ë¶„ì„ ë° ì…ì§€ ì„ ì •
â€¢ ğŸš€ ì°½ì—… ì „ëµ ë° ì‚¬ì—…ê³„íš
â€¢ ğŸ“¢ ë§ˆì¼€íŒ… ë° í™ë³´ ë°©ì•ˆ  
â€¢ ğŸ’° ì •ë¶€ ì§€ì›ì‚¬ì—… ì •ë³´
â€¢ ğŸ“Š ê²½ì˜ ê°œì„  ë°©ì•ˆ

ì–´ë–¤ ë¶„ì•¼ì— ëŒ€í•´ ë„ì›€ì´ í•„ìš”í•˜ì‹ ê°€ìš”?""",
            "context": "",
            "question": question,
            "timestamp": self._get_current_timestamp(),
            "fallback": True
        }
    
    def _get_current_timestamp(self) -> str:
        """í˜„ì¬ ì‹œê°„ ë¬¸ìì—´ ë°˜í™˜"""
        from datetime import datetime
        return datetime.now().isoformat()
